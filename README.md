# Data Science Roadmap
Statement: The purpose of this repo is just to keep track of the progression of my self-study.
## There are few notes that needed to consider before taking a look at this repo:
1. Supervised ML Algorithms:
   - Logistic Regression (almost complete)
    * Define hypothesis and cost function of Logistic Regression
    * Mathematical derivation of the generalized cost function of Logistic Regression
    * Optimization for model parameters via Gradient Descent algorithm & Newton's method
    * Introduce Regularization to the objective function of Logistic Regression
    * Visualization of Decision Boundary when Logistic Regression is applied
    * Logistic Regression as Probabilistic Approach (todo)
   - Multiple Linear Regression (almost complete)
    * Understanding the covariance matrix (done)
    * Multiple Linear Regression with Dummies Exercise (done)
    * Linear Regression as Probabilistic Approach 
        * Difference between Frequentist approach & Bayesian approach
        * Likelihood & Maximum a Posteriori & Posterior Predictive declaration of Linear Regression
        * Examples of tunning parameters of posterior distribution via Metropolis sampling & NUTS sampling (almost done)
   - Gaussian Process (done
    * Introduction (done)
    * Gaussian Process definition & mathematical derivation (done)
    * Implementation
        * Define prior & posterior predictive for GP (done)
        * Prediction with noise-free & noise assumption (done)
        * Examine the affect of hyper parameters of kernel function & noise parameter of data (done)
        * Implementation of GP in higher dimension (done)
        * Libraries of GP implementation (todo)
2. Statistical Concepts
    - Likelihood (todo)
     * Maximum Likelihood Estimation (MLE)
     * Fisher Information & Cramer-Rao Inequality
     * Newton-Raphson Method & Fisher Scoring Method
     * Expectation-Maximization (EM) algorithm
     * Generalized Likelihood Ratio
    - Monte Carlo Sampling
     * Resampling & Bootstrap method
     * Metropolis Hastings Algorithm
     * Gibbs Sampling Algorithm
    - Bayesian Statistics (todo)
     * Normal Model
     * Normal Linear Model
     * Priors & Conjugacy
     * Bayesian Model Comparison
3. Unsupervised ML Algorithms: (todo)
4. Reinforcement Learning: (todo)
5. Clustering Algorithms: (todo)
6. Deep Learning: (todo)
7. More advanced topis: (todo)
